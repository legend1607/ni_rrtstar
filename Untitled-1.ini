Grid-based search methods like A* [7] and D* [8] guarantee to find the optimal path in a discretized state space if a solution exists, at the cost of poor scaling with the problem complexity. Sampling-based algorithms like probabilistic roadmap (PRM) [10] and RRT [11] guarantee to find a feasible path solution if one exists as the number of iterations approaches infinity. PRM* and RRT* [4] provide asymptotic optimality, which requires exploring the planning domain globally. Informed RRT* and Batch Informed Trees improve the convergence rate by constraining the sampling space to a ellipsoidal subset based on start state, goal state, and current best path cost [5], [12]. Another line of works accelerates path planning by investigating the search space of the problem, such as Vonoroi bias [22], [23], evolutionary algorithms [24], and A* initialization [25]. Neural RRT* represents the square-shaped search space of 2D planning problems by images and uses U-Net [26] to predict a probabilistic heatmap of states used for guiding RRT* [6]. MPNet voxelizes environment point cloud and feed into 3D Convolution Neural Networks to make recursive inference for path generation [15]. Gridbased neural networks are prevalent in previous works to encode the search space [6], [13]–[15], [19], which requires discretization operations and the results are dependent on resolution. Previous works use PointNet to encode the point cloud of obstacle states [27], [28], but modeling the obstacle interior is inefficient for finding a path in the free space. Recent works apply graph neural networks to a sampled random geometric graph in configuration space, and select edges from the graph to build a near-optimal path [29], [30]. However, the path feasibility and path quality are highly dependent on the sampled graph, while continuous improvement is not discussed in these works. III. METHOD A. Problem Definition We define the optimal path planning problem similar to related works [4]–[6]. The state space is denoted as X ⊆ Rd. The obstacle space and the free space are denoted as Xobs and Xfree. A path σ : [0, 1] → Xfree is a sequence of states. The set of paths is denoted as Σ. The optimal path planning problem is to find a path σ∗ which minimizes a given cost function c : Σ → R≥0, connects a given start state xstart ∈ Xfree and a given goal state xgoal ∈ Xfree, and has all states on the path in free space. Formally: σ∗ = arg min σ∈Σ c (σ) s.t. σ(0) = xstart, σ(1) =xgoal, ∀s ∈ [0, 1], σ(s) ∈ Xfree (1) B. Neural Informed RRT* We present NIRRT* in Algorithm 1, where the unhighlighted part is from RRT*, the blue part is from IRRT*, and the red part is our contribution. We track the best path solution cost ci best through each iteration, which is initialized as infinity (line 3). We initialize update cost cupdate with the value of c0 best (line 4). We call the neural network to infer an initial guidance state set Xguide based on the complete free state space (line 5). As better solutions are found, the guidance state set Xguide may be updated by the neural network calls depending on how much the path cost has been improved, and random samples xrand are sampled using both Xguide and informed sampling (line 8). PointNetGuidedSampling: When the current best path cost ccurr is less than the path cost improvement ratio α ≤ 1 of cupdate, the neural network is called to update Xguide, and cupdate is updated by ccurr. The random sample xrand is sampled with a mixed strategy: if a random number Rand() ∈ (0, 1) is smaller than 0.5, we use the sampling strategy of IRRT* to sample xrand otherwise, we sample xrand uniformly from Xguide. Similar to [6], [15], [18], our mixed sampling strategy guarantees probabilistic completeness and asymptotic optimality by implementing the sampling procedure of IRRT* with a non-zero probability. Note the frequency of calling neural networks for guidance state inference is controlled by the path cost improvement ratio α. If we do not update Xguide after initial inference, and remove IRRT* components, NIRRT* is reduced to NRRT*. While NIRRT* is generic in that any neural network that infers guidance states can fit into the framework, we emphasize the use of a point-based network. In the next subsection, we discuss the details of Point-based Network Guidance (PNG), and explain the preference of point representations over grid representations. C. Point-based Network Guidance Point-based Network. We represent the state space by a point cloud Xinput = {x1, x2, . . . , xN } ⊂ Xfree. The density of point cloud should allow a reasonable amount of neighbors around each point in radius of step size η. We oversample points uniformly from Xfree, and perform minimum distance downsampling to obtain the point cloud with even distribution. We create a one-hot vector for each point, indicating whether the point is within radius η of xstart or xgoal. We concatenate the one-hot vectors with normalized point coordinates to generate point cloud representations of the free states. The processed point cloud  ̄ Xinput is fed into a point-based network f . The network f maps each point to a probability pi ∈ [0, 1], where the points with probability greater than 0.5 form the set of guidance states Xguide. Formally, {p1, p2, . . . , pN } = f (  ̄ Xinput), Xguide = {xi|pi > 0.5}. (2) We implement PointNet++ [20] as the model architecture of the point-based network. Since PointNet++ is originally designed for 3D point cloud, we set z coordinates as zero for 2D problems. We collect 4,000 2D random worlds as the training dataset. For each random world, we run A* in pixel space with step size of unit pixel and clearance of 3 pixels to generate the pixel-wise optimal path. We generate a point cloud of number N = 2048, and generate guidance state labels by checking whether each point is around any point of the pixel-wise optimal path in radius of η, which is set as 10 pixels. We train PointNet++ by Adam optimizer [31] with an initial learning rate of 0.001 and batch size of 16 for 100 epochs. We use the trained model across all types of 2D planning problems. For 3D random world problems, we follow a similar scheme, but the clearance is set as 2 voxels. Neural Focus. Informed RRT* outperforms RRT* by proposing a heuristic ellipsoidal subset of the planning domain Xfocus in terms of the current best solution cost ccurr, in order to sample xrand which is more likely to improve the current solution. The reasoning behind this sampling strategy is that for any state xrejected from X\Xfocus, the minimum cost of a feasible path from xstart to xgoal through xrejected is greater than ccurr: Xfocus = {x ∈ X  ||x − xstart||2 + ||x − xgoal||2 ≤ ccurr} (3) Neural Focus is to constrain the point cloud input to the point-based network inside the Xfocus, which is equivalent as changing the domain of oversampling from Xfree to Xfocus ∩ Xfree. Since we normalize point coordinates when processing point cloud inputs, the trained point-based network can handle point clouds sampled from domains at different scales. With the same number of points N , a smaller volume of Xfocus leads to a denser point cloud, which describes important regions with finer details. For example, Figure 3(b) shows that Neural Focus fills the narrow passage with a large number of points, which is captured by the point-based network to produce more effective inference on guidance states compared to Figure 3(a). Neural Connect. The points close to xstart or xgoal are usually classified as guidance states with greater probabilities than the points around midway of the path (e.g., Figure 3(d)). When the distance between xstart and xgoal gets longer, the guidance state set Xguide is more likely to be separated into disconnected “blobs”. This phenomenon of probability polarization is reported in NRRT* work [6]. Our experiments show lack of connectivity limits the performance in large and complex planning problems. We address this issue by introducing Neural Connect, which is inspired by RRT-Connect [21]. We initialize Xguide as an empty set, xs1tart as xstart, and x1 goal as xgoal. During iteration, we first call the point-based network with xsitart and xi goal as start and goal, and add inferred guidance states to Xguide. Second, We run Breadth First Search (BFS) from xstart to xgoal through the guidance states in Xguide. The neighbor radius of BFS is set as η, and no collision check is performed. After BFS is finished, connectivity of Xguide is confirmed if xgoal is reached. Otherwise, we find the boundary points Xbound of the states visited by BFS by checking whether any points in Xinput\Xguide are around the visited state of radius η/2. We select xi+1 start from Xbound which is one of the states heuristically the furthest from xstart and one of the states to reach xgoal with minimum total heuristic cost. Third, we perform the same operation as the second step, with the start of BFS as xgoal, and the goal of BFS as xstart. We obtain xi+1 goal if connectivity is negative. We perform the iteration until connectivity is built or the limit of iteration nguide is reached, which we set as 5 in practice. We illustrate Neural Connect in Figure 3(c-h). Note the orange path found by BFS in Figure 3(h) does not go through collision check, so the path is not a feasible solution but a visual demonstration on the connectivity of Xguide. PointNetGuide: We apply both Neural Focus and Neural Connect to the point-based network, and obtain the complete module of Point-based Network Guidance, which is presented in Algorithm 3. Point versus Grid. We prefer using points over grids to represent state space due to compatibility with geometric constraints and convenience of extension to different problems. To apply Neural Focus to a CNN, grid representations require masking of the complement set of the ellipsoidal subset, where the mask quality depends on grid resolution. CNN also has to process the irrelevant masked region within the rectangular/box grid input. In contrast, point representations naturally confine states within arbitrary geometry by modifying the sampling domain, and the point-based network only needs to model free states. Moreover, while the pointbased network just needs adjustment of the input format to extend to different dimensions, changing input dimensions usually requires redesign of CNN architecture.

n this section, we present the Adaptive Trajectory Learning with Obstacle Awareness (ATOA), which involves two phases: (1) offline training with abundant pre-generated environments and expert paths, and (2) online planning for adaptive prediction using a confidence-based search strategy. A. Offline Training 1) Network Architecture: As illustrated in Fig. 1,ATOA consists of an environment encoder and a neural planner. The encoder network E embeds the environment information into a highly nonlinear latent space Z: E(M) → Z. (1) The input environment is formulated as a binary map M, with obstacle areas set to 1 and feasible areas set to 0. Based on the convolutional neural network (CNN) architecture, the encoder network involves five convolutional blocks and five max-pooling operations alternatively, followed by three fully connected layers. The convolutional layers progressively capture the fine-grained spatial details and abstract context. The planner network, consisting of multi-layer perceptrons (MLPs), takes Z as input and incrementally predicts a feasible path. Detailed task definition are as follows. 2) Adaptive Trajectory Learning: The objective of ATOA is to estimate a feasible path from the start state xstart to the goal state xgoal, which is achieved step-by-step. That is, the network is responsible for predicting an intermediate state  ̃ x from the current state xc towards xgoal. Instead of the commonly used state-wise supervision that enforces alignment between  ̃ x and the next state on the expert path (termed path learning) [5], [7], [9], we propose to infer the trajectory along the expert path (termed trajectory learning). Trajectory learning enables the network to adaptively learn intermediate states, which not only facilitates the model’s acquisition of the intrinsic properties of trajectories but also has the potential to yield more effective planning solutions. Specifically, the state displacement from the current state xc to the predicted state  ̃ x is described using hyperspherical coordinates, and the network is responsible for norm ρ regression and direction angle θ classification simultaneously. Adaptive trajectory learning raises three key conditions: (1) The predicted state  ̃ x is required to fall on the expert trajectory while not necessarily aligned with the next state on the expert path. (2) The direction θ should be oriented according to the reference direction on the expert path. (3) The predicted state is expected to have the maximum possible step length ρ to minimize the number of iterations required to reach the goal state. These conditions are achieved through carefully designed loss functions, which are detailed below. a) Trajectory approximation: The intermediate state  ̃ x is encouraged to approach the expert trajectory E, which is approximated as a series of discrete points e through linear interpolation between neighboring states on the expert path. The supervision is applied to the distance between the predicted state  ̃ x and the nearest interpolated point e: Ltra =min e∈E ‖ ̃ x − e‖2. (2) b) Directional consistency: The directional consistency is built upon the assumption that the expert path indicates the step-to-step movement direction from the start state to the goal state. Specifically, the direction from the current state xc to the intermediate state  ̃ x should align with the direction to the next state xc+1 on the expert path. In an n-dimensional state, the displacement between two states is decomposed into a Euclidean norm ρ and (n − 1) direction angles θ =[θ1,θ2,...,θn−1]. By equally dividing the feasible range of i-th angle θi into νi bins, we convert the direction prediction into a multi-class classification task, applying a cross-entropy loss function to each direction: Ldir = n−1 ∑ i=1 Lidir = − n−1 ∑ i=1 νi ∑ j=1 yj i log p(θj i ), (3) where p(θj i ) is the predicted probability for the j-th class of the i-th angle, and yj i denotes the ground truth label that set to 1 for the correct class and 0 for the others. The classification mechanism provides candidate directions along with confidence probabilities, enabling the search strategy to explore alternative feasible solutions when encountering impassable sections, as detailed in Section IV-B2. c) Maximizing forward efficiency: The objective is to maximize the ratio of the distance between xc and  ̃ x to the remaining path length from xc to xgoal on the expert path, within the interval (0, 1]. This strategy allows for the largest possible step length, thereby reaching the goal state with fewer iterations. The loss is defined using a nonlinear function, where the loss value decreases as the ratio approaches 1 and increases when the ratio exceeds 1 to penalize outliers: Lnorm =log(1+exp(−k1(δ − 1))) + α(δ − 1), (4) α= { 0, if 0 <δ≤ 1, k2, if δ>1, (5) δ = ‖ ̃ x − xc‖2 ∑p−1 i=0 ‖xi+1 − xi‖2 , (6) where x0 = xc and xp = xgoal, with (p − 1) intermediate states on the expert path. k1 and k2 control the sensitivity of the decrease and increase in values, respectively. 3) Obstacle Perception Module: Another crucial factor in motion planning is obstacle perception. To enhance the spatial modeling capability of the planner, we explicitly incorporate obstacle information by penalizing predicted trajectories with obstacle collisions. Specifically, obstacle regions Wobs defined in the workspace are projected into the state space to form Xobs.The boundaries A of Xobs are extracted to distinguish the interior and exterior of the obstacle regions. The predicted trajectory is formulated as a series of interpolated states xp between the current state xc and the predicted state  ̃ x. Subsequently, the obstacle loss function is defined as follows: Lobs = 1 Np Np ∑ p=1 exp ( −k3 · φ(xp)min xo∈A d(xp, xo) ) , (7) φ(x)= { 1, M(x)=1, −1, M(x)=0, (8) where Np is the number of interpolated states. d(xp, xo) computes the Euclidean distance between each interpolated state xp and the obstacle boundary point xo. The sign function φ(·) distinguishes between the interior and exterior of obstacles, assigning higher costs to states within obstacles. 4) Total Loss: The total loss is derived by a linear combination of the individual losses, with λ1, λ2, and λ3 balancing the contribution of each component: Ltotal = Ltra + λ1Ldir + λ2Lnorm + λ3Lobs. (9)
用于没有狭窄通道的障碍较少的空旷区域
改进方向：1.PointNet++ + Transformer学习最优路径整体趋势
2 自适应采样策略
目标：集中计算资源在关键区域，避免空旷区域浪费采样。
方法：每找到更优路径后更新启发式采样区域（Xfocus）。
效果：树快速生长到高价值区域，减少无效迭代。
3.重点找最优拐点，障碍周围快速找到最优，空旷区域直连

没有步长也是否也可以1.PointNet++ + Transformer学习最优路径整体趋势 2 自适应采样策略 目标：集中计算资源在关键区域，避免空旷区域浪费采样。 方法： 分区域密度控制：空旷区域低密度采样；关键障碍区域高密度采样。动态更新采样域： 每找到更优路径后更新启发式采样区域（Xfocus）。 效果：树快速生长到高价值区域，减少无效迭代。 3.重点找最优拐点，空旷区域直连

是否可以实现1.PointNet++ + Transformer学习最优路径整体趋势
2 自适应采样策略
目标：集中计算资源在关键区域，避免空旷区域浪费采样。
方法：每找到更优路径后更新启发式采样区域（Xfocus）。
效果：树快速生长到高价值区域，减少无效迭代。
3.重点找最优拐点，障碍周围快速找到最优，空旷区域直连

能否实现
1️⃣ 捕捉全局路径趋势
对 PointNet++ 提取的全局点特征进行自注意力建模。不严格对齐下一状态，而是学习沿专家路径的趋势
输出全局路径趋势表示，包含整个点云的路径趋势信息和关键拐点信息。
作为 RRT 的启发式指导：集中扩展到高价值区域，空旷区域可直连。Transformer 通过全局特征间关系自动学习关键方向。
2️⃣ 自适应采样策略
对每个点计算价值分数，得到高价值区域 Xfocus。
RRT 树快速生长到高价值区域。
RRT 树可以在这些高价值区域集中扩展，空旷区域直连，从而减少无效采样。
3️⃣ 关键拐点 / 高价值区域
精确关键拐点预测,供 RRT 决策使用
Transformer 输出的特征不仅表示整体趋势，也能识别局部关键点（拐点或障碍附近）。

模型同时输出 segmentation (point-level path mask)、point-level关键点概率 和 token-level关键点概率；

训练时让 point-level BCE 和 token-level BCE 共享一部分监督（保证一致性）。

这样，推理时：

segmentation head 给出路径区域；

point-level关键点 head 给出显式关键点（适合直接给 RRT）；

token-level head 给出全局趋势/区域重要性（适合做全局采样和启发式）
在 RRT 里怎么用

路径趋势
→ 用来 bias RRT 的扩展方向，例如把随机采样分布拉向  对应的方向。

高价值区域 
→ 找到高分区域，优先扩展到这些区域。

精确拐点
→ 给出显式的拐点候选，RRT 可以直接尝试连接拐点，减少无效探索。
目的是加速第一次找到可行解的速度和加速树收敛到最优的速度
在 RRT 主循环中，替换/增强采样与扩展策略：

采样（Sample）

每次采样从混合分布采样：with prob p_mix sample from X_focus (importance) else uniform

X_focus 是高价值点或基于概率的重采样区域。

扩展（Extend）偏向高价值

在 extend 过程中，可以把 sample 点替换,若可连接，则尝试 direct_connect；否则，从 nearest 向 sample 做小步长扩展，但优先朝高价值方向（例如对扩展方向做加权）。

直连策略

若两点之间直线无碰撞且两点间空旷且距离大于阈值，则直接连通（skipping intermediate samples）以节省采样。

树增长优先级

当扩展到高价值区域时，给这些节点更高的扩展预算（更多分支尝试），避免浪费在低价值区域。

这些改变是 RRT 层面的，不需要修改模型，只需要 wrapper / RRT 实现调用模型的接口。

输入点云是无碰撞的自由空间均匀分布的状态点
getloss中target 是点云分割标签 (0: free, 1: optimal path points) ，keypoint_label 是每个点是否关键点 (1/0)
如何删除或修改getmodel和getloss，能训练模型
在分类路径和非路径的基础上
学会从起点到拐点到目标点路径上障碍物附近高价值区域：
token_kp_score → 优先扩展 RRT 到高分 token 区域
从起点到目标点路径上障碍物附近关键拐点：
point_kp_score → 直接作为 RRT milestone 点
全局路径趋势：PathShapeHead(global_feat) → 多段方向序列表示全局路径趋势或方向预测。。
技巧：

初期保持较小步长，保证探索。

后期可以动态增大半径，让更多节点参与重连，快速优化全局路径。